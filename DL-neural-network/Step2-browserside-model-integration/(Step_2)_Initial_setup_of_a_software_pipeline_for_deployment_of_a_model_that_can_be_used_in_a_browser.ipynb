{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54_0LHhqdtg"
      },
      "source": [
        "# (Step 2) - Initial setup of a software pipeline for deployment of a model that can be used in a browser\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVGi-xkOqAJ1"
      },
      "source": [
        "The following pipeline uses the Austrian Leaves dataset and sequential model as developed in **(Step 1) - Exploring image dataset Austrian Leaves** ([Colab:](https://colab.research.google.com/drive/15h5ILbqYFrsKk3sYKz5-e4Ln4zJs7HuS?usp=sharing), [Github](https://github.com/TechLabs-Berlin/st22-active-learn-trees/blob/main/DL-neural-network/Step1-exploring-datasets/(Step_1)_Exploring_image_dataset_Austrian_Leaves.ipynb))\n",
        "\n",
        "\n",
        "The final model weights ([DL-neural-network/ai-model](https://github.com/TechLabs-Berlin/st22-active-learn-trees/blob/main//DL-neural-network/ai-model)), and a json file with the categories ([DL-neural-network/ai-model/class_definitions.json](https://github.com/TechLabs-Berlin/st22-active-learn-trees/blob/main/DL-neural-network/ai-model/class_definitions.json)) are stored on github and can be  accessed for browser side classification. \n",
        "The browser side implementation of the model is realised in an [html page -  (tree_identifying-update-links.html) ](https://github.com/TechLabs-Berlin/st22-active-learn-trees/blob/main/DL-neural-network/Step2-browserside-model-integration/tree_identifying-update-links.html) which shows how to upload an image, access the modelweights, classify the image and return the results, this api is now integrated by the WD team with React in our final web application.\n",
        "When downloading the model weights with tensorflow.js not all types of NN layers are supproted, therefore the current model on web application is a very striped down version of the inital NN and therefore not giving accurate predictions. This should definetly be  improved but we thought it was more important to identify a solution to access the model on the browser side, without the need to fully set up a backend. \n",
        "\n",
        "The NN model will be improved in the following steps but still experimentally in a google colab environment. To be able to deploy an updated NN the difficutlties with tensorflow.js would need to be overcome in the future.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp85iLFdtJ_l"
      },
      "source": [
        "#### Setup Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6O9ggE8KaYRW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxVCbGD3ujSD",
        "outputId": "1df869a4-cccc-4b9d-c319-50dd76e9ae1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  135M  100  135M    0     0  9704k      0  0:00:14  0:00:14 --:--:-- 13.3M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://zenodo.org/record/4446955/files/Leaves.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bGmkrybirrdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca43628e-ce4c-4513-9cb4-c39801c6d507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leaves\tLeaves.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "!unzip -q Leaves.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG6Tjk2Y8-n1",
        "outputId": "a92db0a6-4428-4290-ab57-860d3c3167f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ash   Beech   Hornbeam  'Mountain oak'  'Sycamore maple'\n"
          ]
        }
      ],
      "source": [
        "!ls Leaves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2zppG1ce2m1q"
      },
      "outputs": [],
      "source": [
        "species = ['Ash' ,  'Beech'  , 'Hornbeam' , 'Mountain oak' , 'Sycamore maple']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5145153a-bf62-41a6-a7a1-ecca5393d311",
        "id": "o9FhXXKY2m1q"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "len(species)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_3M7euUrtZM"
      },
      "source": [
        "## Image dataset preparation for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4EXtWRVu__RK"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    \"labels\": \"inferred\",\n",
        "    \"label_mode\": \"categorical\",\n",
        "    \"batch_size\": 32,\n",
        "    \"image_size\": (256, 256),\n",
        "    \"seed\": 1,\n",
        "    \"validation_split\": .2,\n",
        "    \"class_names\": species\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZomkyFHAMPf",
        "outputId": "8804bdda-c706-4f8f-e234-e355e9059b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 122 files belonging to 5 classes.\n",
            "Using 98 files for training.\n",
            "Found 122 files belonging to 5 classes.\n",
            "Using 24 files for validation.\n"
          ]
        }
      ],
      "source": [
        "train = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"Leaves\",\n",
        "    subset=\"training\",\n",
        "    **args\n",
        ")\n",
        "\n",
        "test = tf.keras.utils.image_dataset_from_directory(\n",
        "  \"Leaves\",\n",
        "  subset=\"validation\",\n",
        "    **args\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsj4AhXk3BhN"
      },
      "source": [
        "## Train Sequential CNN model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "InMnsPA33BhN"
      },
      "outputs": [],
      "source": [
        "def train_model(network, epochs=5):\n",
        "    model = Sequential(network)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam', # how to predict error/ tries to minimize error \n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "        )\n",
        "    \n",
        "    ## alternative Model compiling\n",
        "    #model.compile(\n",
        "    #    optimizer='rmsprop',\n",
        "    #    loss='binary_crossentropy',\n",
        "    #    metrics=['accuracy']\n",
        "    #    )\n",
        "\n",
        "    history = model.fit(\n",
        "      train,\n",
        "      validation_data=test,\n",
        "      epochs=epochs\n",
        "    )\n",
        "    history_df = pd.DataFrame.from_dict(history.history)\n",
        "    return history_df, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f8fvoJaZ3BhN"
      },
      "outputs": [],
      "source": [
        "network_1 = Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255), # rescale input layer\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256,256,3)), # scan over image and generate new features\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(len(species))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d79e829-9c9f-4fbe-8f34-b89ee8d1d34a",
        "id": "REi1fly43BhN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "4/4 [==============================] - 14s 354ms/step - loss: 130.3583 - accuracy: 0.2143 - val_loss: 4.4660 - val_accuracy: 0.7500\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 2s 270ms/step - loss: 28.9885 - accuracy: 0.3163 - val_loss: 88.2600 - val_accuracy: 0.4583\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 3s 281ms/step - loss: 33.6764 - accuracy: 0.5000 - val_loss: 25.8440 - val_accuracy: 0.4583\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 3s 405ms/step - loss: 4.8730 - accuracy: 0.6531 - val_loss: 9.7021 - val_accuracy: 0.6667\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 3s 279ms/step - loss: 11.1241 - accuracy: 0.5714 - val_loss: 8.6706 - val_accuracy: 0.6667\n"
          ]
        }
      ],
      "source": [
        "history_df, model = train_model(network_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32eX36L-LQlY"
      },
      "source": [
        "## Convert Keras Model to java script readable version using tensorflow js"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Part 2"
      ],
      "metadata": {
        "id": "KAkHU0cd6U4x"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCsuNGl8MTVb"
      },
      "source": [
        "https://www.tensorflow.org/js/tutorials/conversion/import_keras\n",
        "\n",
        "https://www.youtube.com/watch?v=dMq4nAMuqO8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo78fl40M3Hx"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26yt0junnnZz"
      },
      "source": [
        "### Download model to tensorflow js"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rXtNTFrfnkE5"
      },
      "outputs": [],
      "source": [
        "import tensorflowjs as tfjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cpq90Qv3lYC6"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/trees_identifying_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q8jILO5tMKcx"
      },
      "outputs": [],
      "source": [
        "tfjs.converters.save_keras_model(model, 'trees_identifying_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLpYYQFXnt5D"
      },
      "source": [
        "### create zip folder for download of model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um3_eNN0meJ1",
        "outputId": "d34dcd17-826d-42bf-a3ef-6c6342f99365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "tar: strip: Cannot stat: No such file or directory\n",
            "tar: 1: Cannot stat: No such file or directory\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        }
      ],
      "source": [
        "!tar cf trees_identifying_js.tar /content/trees_identifying_model -- strip 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "H76bS911nHFR"
      },
      "outputs": [],
      "source": [
        "!gzip -9 trees_identifying_js.tar"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "(Step 2) - Initial setup of a software pipeline for deployment of a model that can be used in a browser",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}